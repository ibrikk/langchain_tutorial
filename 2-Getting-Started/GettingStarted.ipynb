{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5978cfb",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae49ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# Langsmith Tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a295f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10b576690> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10bf2db90> root_client=<openai.OpenAI object at 0x10b5756d0> root_async_client=<openai.AsyncOpenAI object at 0x10bf2d6d0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c7f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a subset of artificial intelligence technologies that are designed to create new content. This content can range from text and images to audio, video, and even 3D models. Unlike traditional AI models that might classify or predict based on existing data, generative AI models learn patterns from the input data and then use that knowledge to generate entirely new samples that resemble the original data.\\n\\nSome of the key technologies and models driving generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks—a generator and a discriminator—competing against each other. The generator creates new data instances, while the discriminator evaluates them. Through this competition, the generator progressively improves its ability to create realistic data.\\n\\n2. **Variational Autoencoders (VAEs):** These are designed to encode input data into a compressed representation and then decode it back to the original data. VAEs can generate new data by sampling from the latent space derived during encoding.\\n\\n3. **Transformer-based Models:** Models such as OpenAI’s GPT (Generative Pre-trained Transformer) such as GPT-3 or GPT-4 are capable of generating human-like text. These models are pre-trained on vast amounts of data and can produce coherent and contextually accurate text given a prompt.\\n\\nGenerative AI has a wide range of applications across industries, including:\\n\\n- **Content Creation:** Writing articles, generating art, designing objects, and composing music.\\n- **Entertainment:** Creating virtual environments, characters, and scripts.\\n- **Healthcare:** Drug discovery and creating personalized treatment plans.\\n- **Gaming:** Designing levels and scenarios dynamically.\\n\\nDespite its potential, generative AI also brings challenges, particularly in areas like ethical concerns regarding fake content, copyright issues, and the need for regulatory considerations to prevent misuse. As the technology progresses, balancing innovation with ethical guidelines continues to be a critical focus.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 380, 'prompt_tokens': 13, 'total_tokens': 393, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C1h6XOY1mF4mUwtzPF97XctC7F6R6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--52c3bd5e-1e8f-4c63-8d1d-9a9115dd2646-0' usage_metadata={'input_tokens': 13, 'output_tokens': 380, 'total_tokens': 393, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dad055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me asnwers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me asnwers based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b413bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a platform associated with LangChain, designed to enhance the development and management of applications that use large language models (LLMs). It offers a set of tools to assist developers in debugging, testing, evaluating, and monitoring applications that integrate LLMs and AI-driven agents. Key features of Langsmith include providing visibility into application performance, spotting anomalies, and the ability to refine the model's responses for improved accuracy and reliability. This platform aims to streamline the iterative cycle of building and deploying AI applications, making it easier for developers to ensure high performance and reliability in their projects.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 35, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C1h6iJO78FkqFqyOphVHRv4duI7Dl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--945f9576-fd9b-4f4d-a128-a81879fedcfa-0' usage_metadata={'input_tokens': 35, 'output_tokens': 117, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee105b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57380b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform associated with LangChain, which is a framework designed to assist in building applications powered by large language models (LLMs). Langsmith provides a suite of tools and features that enhance the development, testing, and monitoring of LLM-driven applications. This includes capabilities for debugging language model applications, evaluating their performance, and tracking their usage to ensure they produce the desired outputs. Langsmith is particularly valuable for developers and engineers who are looking to maximize the effectiveness and reliability of their applications that rely on language models.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
