{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5978cfb",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae49ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# Langsmith Tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a295f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x11870dba0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11870fe50> root_client=<openai.OpenAI object at 0x11870d300> root_async_client=<openai.AsyncOpenAI object at 0x11870f550> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c7f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence that is designed to create new content. This can include generating text, images, music, or other forms of media, often based on patterns and examples from existing data. Generative AI models, such as Generative Adversarial Networks (GANs) and transformer-based models like GPT (Generative Pre-trained Transformer), learn from large datasets and use this knowledge to produce novel content that resembles the original data in style or form.\\n\\nKey applications of generative AI include creating realistic images, writing essays or articles, developing art, composing music, generating deepfake videos, and more. These models work by understanding the underlying structure of the data they are trained on and using probability-based techniques to generate variations that make sense within the learned framework. Generative AI has seen significant advancements and applications across various industries, though it also raises ethical considerations regarding authenticity, ownership, and potential misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 185, 'prompt_tokens': 13, 'total_tokens': 198, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-C0xufAWb0Jj15AEZw1MTzOxNIV9rI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--68591750-fb34-4bcc-904d-bef7e54d6f12-0' usage_metadata={'input_tokens': 13, 'output_tokens': 185, 'total_tokens': 198, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dad055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me asnwers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me asnwers based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b413bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a toolset introduced by LangChain designed to help developers build, monitor, debug, and evaluate applications constructed with LLMs (Large Language Models). It is essentially tailored to provide developers with the necessary utilities to optimize their use of language models in application development. Key features include monitoring performance, debugging issues that arise, and evaluating the effectiveness of the models being used, thereby improving the overall application development process with LLMs. Langsmith is part of the broader ecosystem that LangChain offers for developers working with generative AI technologies.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 35, 'total_tokens': 144, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C0y7UPx8itW7upuyp3BADB6mdzq15', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--cfef9402-2bb2-4e1d-b696-4cbabeb0886e-0' usage_metadata={'input_tokens': 35, 'output_tokens': 109, 'total_tokens': 144, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee105b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57380b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform associated with LangChain, introduced to enhance the development and deployment of applications powered by large language models (LLMs). This platform provides tools for testing, monitoring, evaluating, and managing LLM-based applications. Key functionalities of Langsmith include:\n",
      "\n",
      "1. **Tracing and Debugging**: It offers detailed insights into how LLMs process and respond to inputs, allowing developers to understand and improve the performance of their language models.\n",
      "\n",
      "2. **Evaluation and Feedback**: Langsmith provides mechanisms for evaluating model outputs against certain criteria, facilitating continuous improvement through feedback loops.\n",
      "\n",
      "3. **Integration with LangChain**: It is seamlessly integrated with LangChain, a framework dedicated to simplifying the use of LLMs, making it easier for developers to build, iterate, and maintain applications that rely on language processing.\n",
      "\n",
      "4. **Monitoring and Management**: The platform includes features for monitoring model usage and performance in real-time, enabling proactive management and scaling of resources.\n",
      "\n",
      "Overall, Langsmith serves as a comprehensive toolkit for developers seeking to optimize the deployment and functionality of language model applications, ensuring they are reliable, effective, and aligned with user expectations.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
